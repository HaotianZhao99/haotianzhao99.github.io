{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8bd36ExHaevg"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before diving into the implementation, we need to set up our authentication with the [Hugging Face Hub](https://huggingface.co/). [Hugging Face](https://huggingface.co/) is a platform that hosts thousands of pre-trained models and datasets, making it an essential resource for modern NLP tasks. This step is crucial if you plan to work with private models or want to save your fine-tuned model to the Hub later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "executionInfo": {
     "elapsed": 555,
     "status": "ok",
     "timestamp": 1734532931004,
     "user": {
      "displayName": "Peaslee Arnetta",
      "userId": "17047474016460582436"
     },
     "user_tz": -480
    },
    "id": "JblvvhPIa9Dl"
   },
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "\n",
    "# Log in to Hugging Face Hub using authentication token\n",
    "# Required for accessing private models and pushing models to Hub\n",
    "login(\"your_token\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading and Preparation\n",
    "For this sentiment analysis task, we'll use a Chinese social media dataset containing 100,000 Weibo posts with sentiment labels. The dataset is hosted on the [Hugging Face Hub](https://huggingface.co/datasets/dirtycomputer/weibo_senti_100k) and can be easily loaded using the `datasets` library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3730,
     "status": "ok",
     "timestamp": 1734532987426,
     "user": {
      "displayName": "Peaslee Arnetta",
      "userId": "17047474016460582436"
     },
     "user_tz": -480
    },
    "id": "xOyJJX2UbDyX",
    "outputId": "45d1a498-3cfa-4e13-b0f8-df3028b16361"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['label', 'review'],\n",
       "        num_rows: 119988\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "\n",
    "# Load sentiment analysis dataset from Hugging Face Hub\n",
    "# Dataset contains 100k Weibo posts with sentiment labels\n",
    "ds = load_dataset(\"dirtycomputer/weibo_senti_100k\")\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3541,
     "status": "ok",
     "timestamp": 1734533042726,
     "user": {
      "displayName": "Peaslee Arnetta",
      "userId": "17047474016460582436"
     },
     "user_tz": -480
    },
    "id": "ChlzAu4-cNoC",
    "outputId": "3d2c3fdb-6898-491d-f050-411b5626a4c7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Overview:\n",
      "Number of samples: 119988\n",
      "Columns: ['label', 'review']\n",
      "\n",
      "Label distribution:\n",
      "label\n",
      "0    59995\n",
      "1    59993\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Sample reviews:\n",
      "0                ÔªøÊõ¥Âçö‰∫ÜÔºåÁàÜÁÖß‰∫ÜÔºåÂ∏ÖÁöÑÂëÄÔºåÂ∞±ÊòØË∂äÊù•Ë∂äÁà±‰Ω†ÔºÅÁîüÂø´ÂÇªÁº∫[Áà±‰Ω†][Áà±‰Ω†][Áà±‰Ω†]\n",
      "1    @Âº†ÊôìÈπèjonathan ÂúüËÄ≥ÂÖ∂ÁöÑ‰∫ãË¶ÅËÆ§ÁúüÂØπÂæÖ[ÂìàÂìà]ÔºåÂê¶ÂàôÁõ¥Êé•ÂºÄÈô§„ÄÇ@‰∏Å‰∏ÅÁúã‰∏ñÁïå ÂæàÊòØÁªÜÂøÉ...\n",
      "2    ÂßëÂ®òÈÉΩÁæ°ÊÖï‰Ω†Âë¢‚Ä¶ËøòÊúâÊãõË¥¢Áå´È´òÂÖ¥‚Ä¶‚Ä¶//@Áà±Âú®ËîìÂª∂-JC:[ÂìàÂìà]Â∞èÂ≠¶Âæí‰∏ÄÊûöÔºåÁ≠âÁùÄÊòéÂ§©ËßÅÊÇ®Âë¢/...\n",
      "3                                           Áæé~~~~~[Áà±‰Ω†]\n",
      "4                                    Ê¢¶ÊÉ≥ÊúâÂ§öÂ§ßÔºåËàûÂè∞Â∞±ÊúâÂ§öÂ§ß![ÈºìÊéå]\n",
      "Name: review, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Convert Hugging Face dataset to pandas DataFrame\n",
    "df = pd.DataFrame(ds['train'])\n",
    "\n",
    "# Display basic information about the DataFrame\n",
    "print(\"Dataset Overview:\")\n",
    "print(f\"Number of samples: {len(df)}\")\n",
    "print(f\"Columns: {df.columns.tolist()}\")\n",
    "print(\"\\nLabel distribution:\")\n",
    "print(df['label'].value_counts())\n",
    "print(\"\\nSample reviews:\")\n",
    "print(df['review'].head())\n",
    "\n",
    "# Check for any missing values\n",
    "if df.isnull().sum().any():\n",
    "    print(\"\\nWarning: Dataset contains missing values!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset contains 119,988 samples. The dataset is perfectly balanced with 59,995 negative samples (label 0) and 59,993 positive samples (label 1). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Splitting\n",
    "Although our dataset is pre-organized, we'll create our own train-test split to ensure we have a fresh evaluation set. We'll use 80% of the data for training and reserve 20% for testing the model's performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "executionInfo": {
     "elapsed": 1016,
     "status": "ok",
     "timestamp": 1734533150658,
     "user": {
      "displayName": "Peaslee Arnetta",
      "userId": "17047474016460582436"
     },
     "user_tz": -480
    },
    "id": "sHMx5XGAcRML"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split dataset into training and test sets\n",
    "# - test_size=0.2: 80% training, 20% testing\n",
    "# - shuffle=True: randomly shuffle before splitting\n",
    "# - random_state=42: set seed for reproducibility\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The key parameters:\n",
    "\n",
    "1. `test_size=0.2`: Creates an 80-20 split, with ~96,000 training samples and ~24,000 test samples\n",
    "2. `shuffle=True`: Ensures random distribution of data, preventing ordering bias\n",
    "3. `random_state=42`: Sets a seed for reproducible results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I run the project on [Google Colab](https://colab.research.google.com), a cloud-based Jupyter notebook environment. Colab provides free GPU access, making it an excellent choice for users without local GPU resources to run deep learning models like BERT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 578,
     "status": "ok",
     "timestamp": 1734533257665,
     "user": {
      "displayName": "Peaslee Arnetta",
      "userId": "17047474016460582436"
     },
     "user_tz": -480
    },
    "id": "lvDROTE0c3_i",
    "outputId": "1f4cb4ff-2cab-4372-ecce-13b5214bc073"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU: NVIDIA A100-SXM4-40GB\n",
      "GPU Memory: 42.48 GB\n"
     ]
    }
   ],
   "source": [
    "# Check for available CUDA device and set up GPU/CPU\n",
    "# Colab typically provides a single GPU, if available\n",
    "if torch.cuda.is_available():\n",
    "   device = torch.device(\"cuda\")\n",
    "   # Print GPU information\n",
    "   print(f\"Using GPU: {torch.cuda.get_device_name(0)}\")\n",
    "   print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "else:\n",
    "   device = torch.device(\"cpu\")\n",
    "   print(\"No GPU available, using CPU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenizer Initialization\n",
    "For our Chinese sentiment analysis task, we'll use the `bert-base-chinese` tokenizer. This pre-trained tokenizer is specifically designed for Chinese text.\n",
    "\n",
    "The tokenizer is crucial for preparing our text data for BERT. It converts Chinese text into tokens that BERT can understand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1734533308977,
     "user": {
      "displayName": "Peaslee Arnetta",
      "userId": "17047474016460582436"
     },
     "user_tz": -480
    },
    "id": "RKh2y5NAdTJZ"
   },
   "outputs": [],
   "source": [
    "# Initialize the BERT Chinese tokenizer\n",
    "# Uses bert-base-chinese pre-trained model's vocabulary\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-chinese')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To efficiently handle our data during training, we need to create a custom Dataset class that inherits from PyTorch's Dataset class. This class will take care of text encoding and provide a standardized way to access our samples.\n",
    "\n",
    "It serves as a data pipeline that:\n",
    "1. Transforms Chinese text into BERT-compatible token IDs\n",
    "2. Ensures consistent input dimensions through padding and truncation\n",
    "3. Efficiently delivers batched data during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "executionInfo": {
     "elapsed": 588,
     "status": "ok",
     "timestamp": 1734533391378,
     "user": {
      "displayName": "Peaslee Arnetta",
      "userId": "17047474016460582436"
     },
     "user_tz": -480
    },
    "id": "znLa0TjXdXBG"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "class TextDataset(Dataset):\n",
    "   \"\"\"\n",
    "   Custom Dataset class for text data, inheriting from PyTorch's Dataset.\n",
    "\n",
    "   Parameters:\n",
    "   tokenizer (Tokenizer): Tokenizer object for text encoding\n",
    "   texts (list): List of text samples\n",
    "   labels (list): List of corresponding labels\n",
    "   \"\"\"\n",
    "   def __init__(self, tokenizer, texts, labels):\n",
    "       # Encode texts with padding and truncation\n",
    "       self.encodings = tokenizer(\n",
    "           texts,\n",
    "           truncation=True,\n",
    "           padding=True,\n",
    "           max_length=512,  # Explicitly set max length for BERT\n",
    "           return_tensors='pt'  # Return PyTorch tensors directly\n",
    "       )\n",
    "       # Convert labels to tensor\n",
    "       self.labels = torch.tensor(labels)\n",
    "\n",
    "   def __getitem__(self, idx):\n",
    "       \"\"\"\n",
    "       Get a single sample by index.\n",
    "\n",
    "       Args:\n",
    "           idx (int): Sample index\n",
    "\n",
    "       Returns:\n",
    "           dict: Dictionary containing encoded text data and label\n",
    "       \"\"\"\n",
    "       return {\n",
    "           'input_ids': self.encodings['input_ids'][idx],\n",
    "           'attention_mask': self.encodings['attention_mask'][idx],\n",
    "           'labels': self.labels[idx]\n",
    "       }\n",
    "\n",
    "   def __len__(self):\n",
    "       \"\"\"\n",
    "       Get dataset length.\n",
    "\n",
    "       Returns:\n",
    "           int: Number of samples in dataset\n",
    "       \"\"\"\n",
    "       return len(self.labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's verify our label distribution and create an explicit mapping for our sentiment classes. While our labels are already in a binary format (0 and 1), maintaining an explicit mapping is a good practice for code clarity and future modifications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 589,
     "status": "ok",
     "timestamp": 1734533411643,
     "user": {
      "displayName": "Peaslee Arnetta",
      "userId": "17047474016460582436"
     },
     "user_tz": -480
    },
    "id": "IJ8z7Q3mP1aw",
    "outputId": "5ea92dfe-7017-455d-d8ef-84b856fa05d9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique labels in training data: [0, 1]\n",
      "\n",
      "Label distribution after mapping:\n",
      "Training: 0    48151\n",
      "1    47839\n",
      "Name: count, dtype: int64\n",
      "Testing: 1    12154\n",
      "0    11844\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Print unique labels in the dataset\n",
    "print(\"Unique labels in training data:\", sorted(set(train_df['label'])))\n",
    "\n",
    "# Create explicit label mapping\n",
    "label_mapping = {\n",
    "    0: 0,  # Negative\n",
    "    1: 1   # Positive\n",
    "}\n",
    "\n",
    "# Map labels using explicit mapping\n",
    "train_labels = [label_mapping[label] for label in train_df['label']]\n",
    "test_labels = [label_mapping[label] for label in test_df['label']]\n",
    "\n",
    "# Verify label distribution after mapping\n",
    "print(\"\\nLabel distribution after mapping:\")\n",
    "print(\"Training:\", pd.Series(train_labels).value_counts())\n",
    "print(\"Testing:\", pd.Series(test_labels).value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 61991,
     "status": "ok",
     "timestamp": 1734533589251,
     "user": {
      "displayName": "Peaslee Arnetta",
      "userId": "17047474016460582436"
     },
     "user_tz": -480
    },
    "id": "wQlQPgdBdaH_",
    "outputId": "b0781a9e-1415-4ff8-db04-d5761339c209"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final verification:\n",
      "Training set label distribution: 0    48151\n",
      "1    47839\n",
      "Name: count, dtype: int64\n",
      "Test set label distribution: 1    12154\n",
      "0    11844\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Explicit label mapping to ensure correct sentiment assignment\n",
    "label_to_index = {\n",
    "    0: 0,  # Keep negative as 0\n",
    "    1: 1   # Keep positive as 1\n",
    "}\n",
    "\n",
    "# Map labels using explicit mapping\n",
    "train_labels = [label_to_index[label] for label in train_df['label']]\n",
    "test_labels = [label_to_index[label] for label in test_df['label']]\n",
    "\n",
    "# Create datasets with verified labels\n",
    "train_dataset = TextDataset(tokenizer, train_df['review'].tolist(), train_labels)\n",
    "test_dataset = TextDataset(tokenizer, test_df['review'].tolist(), test_labels)\n",
    "\n",
    "# Verify final mapping\n",
    "print(\"\\nFinal verification:\")\n",
    "print(\"Training set label distribution:\", pd.Series(train_labels).value_counts())\n",
    "print(\"Test set label distribution:\", pd.Series(test_labels).value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training Setup\n",
    "To fine-tune BERT for our sentiment analysis task, we'll follow these key steps:\n",
    "\n",
    "1. **Model Initialization**: Load the pre-trained Chinese BERT model\n",
    "2. **Training Configuration**: Set up training parameters using `TrainingArguments`\n",
    "3. **Metrics Setup**: Define evaluation metrics for model performance monitoring\n",
    "4. **Trainer Setup**: Initialize the Hugging Face `Trainer` class with:\n",
    "   - The BERT model\n",
    "   - Training arguments\n",
    "   - Training and evaluation datasets\n",
    "   - Metrics computation function\n",
    "5. **Training Process**: Use `trainer.train()` and `trainer.evaluate()` for model fine-tuning and evaluation\n",
    "\n",
    "The Hugging Face Trainer API simplifies the training process by handling the training loops, device management, and model optimization automatically.\n",
    "\n",
    "The code below implements these steps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 692,
     "referenced_widgets": [
      "714699c43aa54ec48feb28ad4211e94b",
      "d63fd88293ed44ecb76f240cd681d395",
      "a270a9496563465a9da9d39a12adbe8e",
      "f40ffd10d911413a948471d95a4b6124",
      "b8f81a6edd33498090ca9769a18237f4",
      "e78638e914e141d68a24f2dd12d8b093",
      "f7a0d4cf9fdf4ebcb5ce2a52fe4b7701",
      "cee4d6c1370d4b54b13dab27eb540c21",
      "31be18fc303a41faa68b12fd3871dd1f",
      "7d9627cb192945809b2cc6eb35db3dc7",
      "d2557dacf6744e608e074b2d7e0a1013"
     ]
    },
    "executionInfo": {
     "elapsed": 2767603,
     "status": "ok",
     "timestamp": 1734536476453,
     "user": {
      "displayName": "Peaslee Arnetta",
      "userId": "17047474016460582436"
     },
     "user_tz": -480
    },
    "id": "m48Mjw8Oduma",
    "outputId": "37cd882b-62f0-4d07-e5a6-02a51a4ffeea"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "714699c43aa54ec48feb28ad4211e94b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/412M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-chinese and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ü§ó Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Configuration:\n",
      "Model: bert-base-chinese\n",
      "Training samples: 95990\n",
      "Test samples: 23998\n",
      "Batch size: 32\n",
      "Number of epochs: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
       "            function loadScript(url) {\n",
       "            return new Promise(function(resolve, reject) {\n",
       "                let newScript = document.createElement(\"script\");\n",
       "                newScript.onerror = reject;\n",
       "                newScript.onload = resolve;\n",
       "                document.body.appendChild(newScript);\n",
       "                newScript.src = url;\n",
       "            });\n",
       "            }\n",
       "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
       "            const iframe = document.createElement('iframe')\n",
       "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
       "            document.body.appendChild(iframe)\n",
       "            const handshake = new Postmate({\n",
       "                container: iframe,\n",
       "                url: 'https://wandb.ai/authorize'\n",
       "            });\n",
       "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
       "            handshake.then(function(child) {\n",
       "                child.on('authorize', data => {\n",
       "                    clearTimeout(timeout)\n",
       "                    resolve(data)\n",
       "                });\n",
       "            });\n",
       "            })\n",
       "        });\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
      "wandb: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/content/wandb/run-20241218_150159-oimgwuen</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/zhaohaotian99-huazhong-university-of-science-and-technology/huggingface/runs/oimgwuen' target=\"_blank\">sentiment-weibo-100k-fine-tuned-bert</a></strong> to <a href='https://wandb.ai/zhaohaotian99-huazhong-university-of-science-and-technology/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/zhaohaotian99-huazhong-university-of-science-and-technology/huggingface' target=\"_blank\">https://wandb.ai/zhaohaotian99-huazhong-university-of-science-and-technology/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/zhaohaotian99-huazhong-university-of-science-and-technology/huggingface/runs/oimgwuen' target=\"_blank\">https://wandb.ai/zhaohaotian99-huazhong-university-of-science-and-technology/huggingface/runs/oimgwuen</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='9000' max='9000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [9000/9000 38:15, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.033300</td>\n",
       "      <td>0.039774</td>\n",
       "      <td>0.984040</td>\n",
       "      <td>0.983992</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.968488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.034900</td>\n",
       "      <td>0.037043</td>\n",
       "      <td>0.983790</td>\n",
       "      <td>0.983737</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.967994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.037600</td>\n",
       "      <td>0.036484</td>\n",
       "      <td>0.984040</td>\n",
       "      <td>0.983992</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.968488</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No files have been modified since last commit. Skipping to prevent empty commit.\n",
      "WARNING:huggingface_hub.hf_api:No files have been modified since last commit. Skipping to prevent empty commit.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='375' max='375' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [375/375 00:50]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation Results: {'eval_loss': 0.03648396208882332, 'eval_accuracy': 0.9840403366947246, 'eval_f1': 0.9839916405433646, 'eval_precision': 1.0, 'eval_recall': 0.9684877406615107, 'eval_runtime': 50.6448, 'eval_samples_per_second': 473.849, 'eval_steps_per_second': 7.405, 'epoch': 3.0}\n"
     ]
    }
   ],
   "source": [
    "# Load pre-trained Chinese BERT model and configure for binary classification\n",
    "model = BertForSequenceClassification.from_pretrained(\n",
    "   'bert-base-chinese',\n",
    "   num_labels=2  # Binary classification (negative/positive)\n",
    ")\n",
    "model = model.to(device)\n",
    "\n",
    "# Define training arguments for model fine-tuning\n",
    "training_args = TrainingArguments(\n",
    "   output_dir='sentiment-weibo-100k-fine-tuned-bert-test',  # Directory to save model checkpoints\n",
    "   num_train_epochs=3,                                 # Number of training epochs\n",
    "   per_device_train_batch_size=32,                    # Number of samples per training batch\n",
    "   per_device_eval_batch_size=64,                     # Number of samples per evaluation batch\n",
    "   warmup_steps=500,                                  # Steps for learning rate warmup\n",
    "   weight_decay=0.01,                                 # L2 regularization factor\n",
    "   logging_dir='./logs',                             # Directory for training logs\n",
    "   logging_steps=100,                                # Log metrics every 100 steps\n",
    "   evaluation_strategy=\"epoch\",                      # Evaluate after each epoch\n",
    "   save_strategy=\"epoch\",                           # Save model after each epoch\n",
    "   load_best_model_at_end=True,                    # Load best model after training\n",
    "   push_to_hub=True,                               # Push model to Hugging Face Hub\n",
    "   learning_rate=2e-5,                             # Initial learning rate\n",
    "   gradient_accumulation_steps=1                   # Update model after every batch\n",
    ")\n",
    "\n",
    "def compute_metrics(pred):\n",
    "   \"\"\"\n",
    "   Compute evaluation metrics for the model\n",
    "   Args:\n",
    "       pred: Contains predictions and label_ids\n",
    "   Returns:\n",
    "       dict: Dictionary containing accuracy, F1, precision, and recall scores\n",
    "   \"\"\"\n",
    "   labels = pred.label_ids\n",
    "   preds = pred.predictions.argmax(-1)\n",
    "   precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "       labels,\n",
    "       preds,\n",
    "       average='binary',\n",
    "       pos_label=1  # Define positive class for binary metrics\n",
    "   )\n",
    "   acc = accuracy_score(labels, preds)\n",
    "\n",
    "   return {\n",
    "       'accuracy': acc,\n",
    "       'f1': f1,\n",
    "       'precision': precision,\n",
    "       'recall': recall\n",
    "   }\n",
    "\n",
    "# Initialize trainer with model and training configuration\n",
    "trainer = Trainer(\n",
    "   model=model,\n",
    "   args=training_args,\n",
    "   train_dataset=train_dataset,\n",
    "   eval_dataset=test_dataset,\n",
    "   compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "# Print training configuration summary\n",
    "print(\"Training Configuration:\")\n",
    "print(f\"Model: bert-base-chinese\")\n",
    "print(f\"Training samples: {len(train_dataset)}\")\n",
    "print(f\"Test samples: {len(test_dataset)}\")\n",
    "print(f\"Batch size: {training_args.per_device_train_batch_size}\")\n",
    "print(f\"Number of epochs: {training_args.num_train_epochs}\")\n",
    "\n",
    "# Start training\n",
    "trainer.train()\n",
    "\n",
    "# Evaluate model performance\n",
    "eval_results = trainer.evaluate()\n",
    "print(\"\\nEvaluation Results:\", eval_results)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "31be18fc303a41faa68b12fd3871dd1f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "714699c43aa54ec48feb28ad4211e94b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_d63fd88293ed44ecb76f240cd681d395",
       "IPY_MODEL_a270a9496563465a9da9d39a12adbe8e",
       "IPY_MODEL_f40ffd10d911413a948471d95a4b6124"
      ],
      "layout": "IPY_MODEL_b8f81a6edd33498090ca9769a18237f4"
     }
    },
    "7d9627cb192945809b2cc6eb35db3dc7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a270a9496563465a9da9d39a12adbe8e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_cee4d6c1370d4b54b13dab27eb540c21",
      "max": 411553788,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_31be18fc303a41faa68b12fd3871dd1f",
      "value": 411553788
     }
    },
    "b8f81a6edd33498090ca9769a18237f4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cee4d6c1370d4b54b13dab27eb540c21": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d2557dacf6744e608e074b2d7e0a1013": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d63fd88293ed44ecb76f240cd681d395": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e78638e914e141d68a24f2dd12d8b093",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_f7a0d4cf9fdf4ebcb5ce2a52fe4b7701",
      "value": "model.safetensors:‚Äá100%"
     }
    },
    "e78638e914e141d68a24f2dd12d8b093": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f40ffd10d911413a948471d95a4b6124": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7d9627cb192945809b2cc6eb35db3dc7",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_d2557dacf6744e608e074b2d7e0a1013",
      "value": "‚Äá412M/412M‚Äá[00:02&lt;00:00,‚Äá201MB/s]"
     }
    },
    "f7a0d4cf9fdf4ebcb5ce2a52fe4b7701": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
