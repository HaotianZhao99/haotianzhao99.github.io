<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> PopBert：Unveiling Populist Language in Political Discourse | Haotian Zhao </title> <meta name="author" content="Haotian Zhao"> <meta name="description" content="In this project, I am learning and replicating the key steps in building the PopBERT model from the research " popbert. detecting populism and its host ideologies in the german bundestag by erhard et al. this study develops a transformer-based model to detect populist language parliamentary speeches focusing on moralizing references virtuous people corrupt elite.> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%F0%9F%93%A1&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://haotianzhao99.github.io/projects/popbert/"> <script src="/assets/js/theme.js?9a0c749ec5240d9cda97bc72359a72c0"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>initTheme();</script> </head> <body class="fixed-top-nav sticky-bottom-footer"> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Haotian</span> Zhao </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">home </a> </li> <li class="nav-item "> <a class="nav-link" href="/academicpapers/">academic papers </a> </li> <li class="nav-item active"> <a class="nav-link" href="/projects/">projects <span class="sr-only">(current)</span> </a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">PopBert：Unveiling Populist Language in Political Discourse</h1> <p class="post-description">In this project, I am learning and replicating the key steps in building the PopBERT model from the research "PopBERT. Detecting Populism and Its Host Ideologies in the German Bundestag" by Erhard et al. (2024). This study develops a transformer-based model to detect populist language in German parliamentary speeches, focusing on the moralizing references to "the virtuous people" and "the corrupt elite."</p> </header> <article> <p>PopBERT is a transformer-based language model developed by researchers at the University of Stuttgart to detect populist language in German political discourse. The study focuses on analyzing speeches from the German Bundestag (parliament) between 2013-2021. The model was trained to identify two core dimensions of populism: anti-elitism and people-centrism, along with their associated left-wing and right-wing host ideologies. Using GBERTLarge as its foundation, PopBERT demonstrates strong performance in detecting these populist elements in political speeches. The researchers validated the model through multiple approaches, including comparison with expert surveys and out-of-sample testing. This tool enables researchers to conduct dynamic analyses of how German-speaking politicians and parties employ populist language as a strategic device.</p> <p>In this project, we will study and reproduce the key steps of PopBERT, focusing on its transformer-based architecture for detecting populist language. We’ll pay particular attention to understanding its data preprocessing steps, model architecture based on GBERTLarge, and the multi-label classification approach for identifying both core populist dimensions and their host ideologies.</p> <h1 id="training-the-model">Training the Model</h1> <p>The code used in this project comes from the original authors’ open-source repository on <a href="https://github.com/luerhard/PopBERT" rel="external nofollow noopener" target="_blank">GitHub</a>. I have cloned the repository to Google Drive and will be running the experiments on <a href="https://colab.research.google.com/" rel="external nofollow noopener" target="_blank">Google Colab</a> for its accessible GPU resources and easy integration with Drive.</p> <p>The following sections will walk through the key steps of model training and implementation.</p> <h2 id="a-glimpse-into-the-dataset">A Glimpse into the Dataset</h2> <table> <thead> <tr> <th>id</th> <th>text</th> <th>username</th> <th>elite</th> <th>centr</th> <th>left</th> <th>right</th> </tr> </thead> <tbody> <tr> <td>446633</td> <td>Ihre willkürliche Zusammenstellung und Auflistung alter Forderungen zeigt, dass Sie nicht willens sind, einen verantwortlichen und gesellschaftlich akzeptierbaren Beitrag zum Tierschutz in Deutschland zu leisten, sondern dass Sie Emotionen schüren wollen.</td> <td>riedel</td> <td>True</td> <td>False</td> <td>False</td> <td>False</td> </tr> <tr> <td>446633</td> <td>Ihre willkürliche Zusammenstellung und Auflistung alter Forderungen zeigt, dass Sie nicht willens sind, einen verantwortlichen und gesellschaftlich akzeptierbaren Beitrag zum Tierschutz in Deutschland zu leisten, sondern dass Sie Emotionen schüren wollen.</td> <td>richter</td> <td>False</td> <td>False</td> <td>False</td> <td>False</td> </tr> <tr> <td>446633</td> <td>Ihre willkürliche Zusammenstellung und Auflistung alter Forderungen zeigt, dass Sie nicht willens sind, einen verantwortlichen und gesellschaftlich akzeptierbaren Beitrag zum Tierschutz in Deutschland zu leisten, sondern dass Sie Emotionen schüren wollen.</td> <td>grabsch</td> <td>False</td> <td>False</td> <td>False</td> <td>False</td> </tr> <tr> <td>119028</td> <td>Einen ganz herzlichen Dank an diese Kolleginnen und Kollegen, an die Mitarbeiter des Ausschusses und alle Bürgerinnen und Bürger, die sich aktiv für unser Gemeinwohl einsetzen.</td> <td>schadt</td> <td>False</td> <td>False</td> <td>False</td> <td>False</td> </tr> <tr> <td>119028</td> <td>Einen ganz herzlichen Dank an diese Kolleginnen und Kollegen, an die Mitarbeiter des Ausschusses und alle Bürgerinnen und Bürger, die sich aktiv für unser Gemeinwohl einsetzen.</td> <td>coudry</td> <td>False</td> <td>False</td> <td>False</td> <td>False</td> </tr> </tbody> </table> <p>[35180 rows x 7 columns]<br> Total annotations: 35180<br> Number of labels: 4 (elite, centr, left, right)<br> Number of unique texts: 7036<br> Samples with labels: 3515 (49.96%)<br> Samples without labels(all annotators marked all 4 label dimensions as zero): 3521 (50.04%)</p> <h2 id="create-popbert-model">Create PopBERT Model</h2> <p> <script src="https://gist.github.com/HaotianZhao99/77ff120266c5a221c0f18701c6c5d45e.js"></script> </p> <p>In the code above, we can see the main framework of the training process, including optimizer setup, learning rate scheduling strategy, and the main training loop. However, to deeply understand how the model is specifically trained, we need to examine the implementation of train_epoch and eval_epoch functions in the <code class="language-plaintext highlighter-rouge">training.py</code> file.</p> <h2 id="trainingpy-understanding-the-training-implementation"> <code class="language-plaintext highlighter-rouge">training.py</code>: Understanding the Training Implementation</h2> <p>The author encapsulates the specific implementations through different Python modules in the src(source) directory. This modular design makes the code structure clearer and easier to maintain and reuse.</p> <p>Next, we will delve into the implementation details in the training.py file. This file contains the core logic of model training. By analyzing the code line by line, we can better understand the specific operational steps, loss calculation methods, and evaluation approaches during the BERT model training process. We will pay special attention to the implementation of two key functions: train_epoch and eval_epoch.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="n">torch</span>
<span class="kn">from</span> <span class="n">sklearn.metrics</span> <span class="kn">import</span> <span class="n">f1_score</span>

<span class="kn">import</span> <span class="n">src.bert.utils</span> <span class="k">as</span> <span class="n">bert_utils</span>
</code></pre></div></div> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">DEVICE</span> <span class="o">=</span> <span class="sh">"</span><span class="s">cuda</span><span class="sh">"</span> <span class="k">if</span> <span class="n">torch</span><span class="p">.</span><span class="n">cuda</span><span class="p">.</span><span class="nf">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="sh">"</span><span class="s">cpu</span><span class="sh">"</span>
</code></pre></div></div> <p>Uses “cuda” if GPU is available. This <code class="language-plaintext highlighter-rouge">DEVICE</code> variable will be used to specify where the model and data should run</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">train_epoch</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">dataloader</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">lr_scheduler</span><span class="p">,</span> <span class="n">clip</span><span class="p">):</span>
    <span class="n">train_loss</span> <span class="o">=</span> <span class="mf">0.0</span>                         <span class="c1"># Initialize total loss
</span>    <span class="n">model</span><span class="p">.</span><span class="nf">train</span><span class="p">()</span>                            <span class="c1"># Set model to training mode
</span>    <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">dataloader</span><span class="p">:</span>
        <span class="n">optimizer</span><span class="p">.</span><span class="nf">zero_grad</span><span class="p">()</span>                <span class="c1"># Clear previous gradients
</span>        
        <span class="c1"># Move data to device and forward propagation
</span>        <span class="n">encodings</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="sh">"</span><span class="s">encodings</span><span class="sh">"</span><span class="p">].</span><span class="nf">to</span><span class="p">(</span><span class="n">DEVICE</span><span class="p">)</span>
        <span class="n">labels</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="sh">"</span><span class="s">labels</span><span class="sh">"</span><span class="p">].</span><span class="nf">to</span><span class="p">(</span><span class="n">DEVICE</span><span class="p">)</span>
        <span class="n">out</span> <span class="o">=</span> <span class="nf">model</span><span class="p">(</span><span class="o">**</span><span class="n">encodings</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="n">labels</span><span class="p">)</span>

        <span class="n">out</span><span class="p">.</span><span class="n">loss</span><span class="p">.</span><span class="nf">backward</span><span class="p">()</span>                  <span class="c1"># Calculate gradients
</span>        <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">utils</span><span class="p">.</span><span class="nf">clip_grad_norm_</span><span class="p">(</span><span class="n">model</span><span class="p">.</span><span class="nf">parameters</span><span class="p">(),</span> <span class="n">clip</span><span class="p">)</span>   <span class="c1"># Gradient clipping
</span>        <span class="n">optimizer</span><span class="p">.</span><span class="nf">step</span><span class="p">()</span>                     <span class="c1"># Update model parameters
</span>        <span class="n">lr_scheduler</span><span class="p">.</span><span class="nf">step</span><span class="p">()</span>                  <span class="c1"># Update learning rate
</span>
        <span class="n">train_loss</span> <span class="o">+=</span> <span class="n">out</span><span class="p">.</span><span class="n">loss</span><span class="p">.</span><span class="nf">item</span><span class="p">()</span>        <span class="c1"># Accumulate batch loss
</span>
    <span class="k">return</span> <span class="n">train_loss</span>
</code></pre></div></div> <p>Key Steps</p> <ul> <li> <p>Gradient Zeroing <code class="language-plaintext highlighter-rouge">optimizer.zero_grad()</code></p> <p>In machine learning, a gradient is a vector that represents the rate of change of the loss function at the current point. Imagine you’re on a mountain, blindfolded, and need to find your way to the bottom (similar to finding the minimum of a loss function in machine learning). In this case, the gradient is like the slope of the ground beneath your feet. The gradient tells you two important pieces of information:</p> <ol> <li>The direction of the slope (whether it’s going up or down)</li> <li>The steepness of the slope (whether it’s steep or gentle)</li> </ol> <p>Therefore, if we want to minimize the loss, we need to move in the opposite direction of the gradient.</p> <p>Before each batch, we must clear previously accumulated gradients. Without zeroing, new gradients would add to old ones, leading to inaccurate parameter updates.</p> </li> <li> <p>Forward Propagation <code class="language-plaintext highlighter-rouge">out = model(**encodings, labels=labels)</code></p> <p>In a BERT model, when we input a sentence, it first gets converted into numbers (word embeddings). These numbers then pass through each layer of the model sequentially. Each layer performs specific mathematical operations and transformations on these numbers, ultimately producing the result we need (like text classification predictions).</p> <p>The data flows forward like a stream, transforming layer by layer until we get our desired output. Each layer contributes its own processing to the final prediction. This is why we call it “forward” propagation, as data flows from input towards output direction.</p> </li> <li> <p>Backward Propagation <code class="language-plaintext highlighter-rouge">out.loss.backward()</code></p> <p>In deep learning, backpropagation is the model’s process of “looking back.” After making a prediction, the model calculates the error (loss) between predicted and actual values, then works backwards from the output layer, calculating how much each parameter contributed to this error. It’s like unraveling a chain of cause and effect to figure out “which parameters need adjustment and by how much” to reduce prediction errors.</p> <p>In PyTorch, the <code class="language-plaintext highlighter-rouge">backward()</code> method is the core of automatic differentiation. When we call <code class="language-plaintext highlighter-rouge">out.loss.backward()</code>, PyTorch starts from the loss value and performs backpropagation through the computational graph, calculating how each parameter influenced the loss (gradients).</p> </li> <li> <p>Gradient Clipping <code class="language-plaintext highlighter-rouge">torch.nn.utils.clip_grad_norm_(model.parameters(), clip)</code></p> <p>In deep learning, when gradient values become too large, model training can become unstable. Gradient clipping works by setting a threshold - when gradients exceed this threshold, they are proportionally scaled down to keep them within a reasonable range. This prevents “explosion” phenomena during model training and makes the training process more stable.</p> </li> <li> <p>Parameter Update <code class="language-plaintext highlighter-rouge">optimizer.step()</code></p> <p>Updates model parameters using the optimizer (in this study, AdamW) based on computed gradients. The optimizer determines how to adjust parameters using gradient information.</p> <p>AdamW is a widely used optimization algorithm, an improved version of Adam optimizer. It combines two important ideas: adaptive learning rates and weight decay. Like an experienced teacher, it knows when to take big steps in learning (larger learning rate) and when to slow down for careful consideration (smaller learning rate).</p> </li> <li> <p>Learning Rate Adjustment <code class="language-plaintext highlighter-rouge">lr_scheduler.step()</code></p> <p>Adjusts learning rate according to a preset strategy.</p> </li> </ul> <p>These steps form the basic training loop in deep learning</p> <hr> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">eval_epoch</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">dataloader</span><span class="p">):</span>
    <span class="n">eval_loss</span> <span class="o">=</span> <span class="mf">0.0</span>
    <span class="n">y_true</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">y_pred</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">model</span><span class="p">.</span><span class="nf">eval</span><span class="p">()</span>             <span class="c1"># Switch the model to evaluation mode
</span>    <span class="k">with</span> <span class="n">torch</span><span class="p">.</span><span class="nf">inference_mode</span><span class="p">():</span>
        <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">dataloader</span><span class="p">:</span>
            <span class="n">encodings</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="sh">"</span><span class="s">encodings</span><span class="sh">"</span><span class="p">]</span>
            <span class="n">encodings</span> <span class="o">=</span> <span class="n">encodings</span><span class="p">.</span><span class="nf">to</span><span class="p">(</span><span class="n">DEVICE</span><span class="p">)</span>
            <span class="n">labels</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="sh">"</span><span class="s">labels</span><span class="sh">"</span><span class="p">].</span><span class="nf">to</span><span class="p">(</span><span class="n">DEVICE</span><span class="p">)</span>
            <span class="n">out</span> <span class="o">=</span> <span class="nf">model</span><span class="p">(</span><span class="o">**</span><span class="n">encodings</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="n">labels</span><span class="p">)</span>        <span class="c1">#Feed the feature vectors into the model, obtaining the output out which contains logits and loss.
</span>            <span class="k">if</span> <span class="n">model</span><span class="p">.</span><span class="n">config</span><span class="p">.</span><span class="n">problem_type</span> <span class="o">==</span> <span class="sh">"</span><span class="s">multi_label_classification</span><span class="sh">"</span><span class="p">:</span>
                <span class="n">preds</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">functional</span><span class="p">.</span><span class="nf">sigmoid</span><span class="p">(</span><span class="n">out</span><span class="p">.</span><span class="n">logits</span><span class="p">)</span>
            <span class="k">elif</span> <span class="n">model</span><span class="p">.</span><span class="n">config</span><span class="p">.</span><span class="n">problem_type</span> <span class="o">==</span> <span class="sh">"</span><span class="s">single_label_classification</span><span class="sh">"</span><span class="p">:</span>
                <span class="n">preds</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">functional</span><span class="p">.</span><span class="nf">softmax</span><span class="p">(</span><span class="n">out</span><span class="p">.</span><span class="n">logits</span><span class="p">)</span>

            <span class="n">eval_loss</span> <span class="o">+=</span> <span class="n">out</span><span class="p">.</span><span class="n">loss</span><span class="p">.</span><span class="nf">item</span><span class="p">()</span>
            <span class="n">y_true</span><span class="p">.</span><span class="nf">extend</span><span class="p">(</span><span class="n">batch</span><span class="p">[</span><span class="sh">"</span><span class="s">labels</span><span class="sh">"</span><span class="p">].</span><span class="nf">numpy</span><span class="p">())</span>
            <span class="n">y_pred</span><span class="p">.</span><span class="nf">extend</span><span class="p">(</span><span class="n">preds</span><span class="p">.</span><span class="nf">to</span><span class="p">(</span><span class="sh">"</span><span class="s">cpu</span><span class="sh">"</span><span class="p">).</span><span class="nf">detach</span><span class="p">().</span><span class="nf">numpy</span><span class="p">())</span>

    <span class="n">y_true</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">(</span><span class="n">y_true</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">model</span><span class="p">.</span><span class="n">config</span><span class="p">.</span><span class="n">problem_type</span> <span class="o">==</span> <span class="sh">"</span><span class="s">multi_label_classification</span><span class="sh">"</span><span class="p">:</span>
        <span class="n">y_pred_bin</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">where</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">(</span><span class="n">y_pred</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
        <span class="n">thresh_finder</span> <span class="o">=</span> <span class="n">bert_utils</span><span class="p">.</span><span class="nc">ThresholdFinder</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="sh">"</span><span class="s">single_task</span><span class="sh">"</span><span class="p">)</span>
        <span class="n">thresholds</span> <span class="o">=</span> <span class="n">thresh_finder</span><span class="p">.</span><span class="nf">find_thresholds</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">(</span><span class="n">y_true</span><span class="p">),</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">(</span><span class="n">y_pred</span><span class="p">))</span>
    <span class="k">elif</span> <span class="n">model</span><span class="p">.</span><span class="n">config</span><span class="p">.</span><span class="n">problem_type</span> <span class="o">==</span> <span class="sh">"</span><span class="s">single_label_classification</span><span class="sh">"</span><span class="p">:</span>
        <span class="n">y_pred_bin</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">argmax</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">(</span><span class="n">y_pred</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">thresholds</span> <span class="o">=</span> <span class="p">{</span><span class="n">k</span><span class="p">:</span> <span class="mf">0.5</span> <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">model</span><span class="p">.</span><span class="n">config</span><span class="p">.</span><span class="n">num_labels</span><span class="p">)}</span>

    <span class="n">score</span> <span class="o">=</span> <span class="nf">f1_score</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">(</span><span class="n">y_true</span><span class="p">),</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">(</span><span class="n">y_pred_bin</span><span class="p">),</span> <span class="n">average</span><span class="o">=</span><span class="sh">"</span><span class="s">macro</span><span class="sh">"</span><span class="p">,</span> <span class="n">zero_division</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">eval_loss</span><span class="p">,</span> <span class="n">score</span><span class="p">,</span> <span class="n">thresholds</span>
</code></pre></div></div> <p>This code defines a function eval_epoch to evaluate the performance of the model.</p> <ul> <li> <p>Single-label classification:</p> <p>In single-label classification, the model outputs a probability distribution processed through <code class="language-plaintext highlighter-rouge">softmax</code>, where each class’s probability sums to 1. During prediction, the class with the highest probability is selected as the final prediction.</p> </li> <li> <p>Multi-label classification:<br> In multi-label classification, the model outputs independent probabilities for each label, indicating the likelihood of the sample belonging to each class. During prediction, a threshold (e.g., 0.5) is usually applied: if the probability of a class exceeds this threshold, the sample is considered to belong to that class.</p> </li> <li> <p>F1 Score Calculation In single-label classification, <code class="language-plaintext highlighter-rouge">argmax</code> is used to select the predicted class for each sample. This means the model makes one prediction per sample.</p> <p>In multi-label classification, since each sample can belong to multiple labels, F1 scores are computed by comparing the binarized predictions with the true labels. In the code, <code class="language-plaintext highlighter-rouge">np.where</code> is used to convert probabilities into binary values (0 or 1), and then a macro average F1 score is calculated.</p> </li> </ul> <hr> <h1 id="testing-with-our-trained-model">Testing with Our Trained Model</h1> <p>Now that we’ve successfully trained our model, let’s test it on a few example instances. Using the fine-tuned model, we can input several sentences and observe how well the model performs in classifying them.</p> <p> <script src="https://gist.github.com/HaotianZhao99/6e37a259ded5212a476068866a71cdc9.js"></script> </p> <p>Overall, our trained model performed well, successfully distinguishing Anti-elitism, People-centrism, Left-wing, and Right-wing, as well as identifying sentences that exhibit both Anti-elitism and People-centrism.</p> </article> </div> </div> <footer class="sticky-bottom mt-5" role="contentinfo"> <div class="container"> © Copyright 2025 Haotian Zhao. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>addBackToTop();</script> </body> </html>